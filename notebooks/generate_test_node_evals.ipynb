{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f39c9143",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "sys.path.append(os.path.abspath(\"..\"))\n",
    "\n",
    "from langsmith import Client\n",
    "from typing import TypedDict\n",
    "from typing_extensions import Annotated\n",
    "from langchain.chat_models import init_chat_model\n",
    "from src.agent import graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f83c0ab2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'example_ids': ['4ea66859-98cd-4102-9b42-962b52c78b56',\n",
       "  'bf08d7fc-8473-42a9-aa94-32ec51f7899c',\n",
       "  '817c9cf1-87ae-4de0-8a87-690c9415a5de',\n",
       "  '4918ef7a-4409-4373-92ee-99eec58b7ac4',\n",
       "  'b9d7557b-c8eb-4880-aa48-d7b656ecdaf8',\n",
       "  '558301d9-8d07-4f1e-a9f6-9a2d16a81141',\n",
       "  '57ca4968-4c99-49bb-a77e-12d85f6e3abf',\n",
       "  '8da93b5c-500b-490d-aa47-015f44d3b2b5'],\n",
       " 'count': 8}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langsmith import Client\n",
    "\n",
    "client = Client()\n",
    "dataset_name = \"test_the_correct_tests_are_generated\"\n",
    "\n",
    "examples = [\n",
    "    # 1) add_two_numbers\n",
    "    {\n",
    "        \"inputs\": {\"code\": \"def add_two_numbers(a: int, b: int) -> int:\\n    return a + b\"},\n",
    "        \"outputs\": {\n",
    "            \"tests\": {\n",
    "                \"function_name\": \"add_two_numbers\",\n",
    "                \"tests\": [\n",
    "                    {\"args\": [1, 2], \"kwargs\": {}, \"expect\": 3},\n",
    "                    {\"args\": [0, 0], \"kwargs\": {}, \"expect\": 0},\n",
    "                    {\"args\": [-5, 2], \"kwargs\": {}, \"expect\": -3},\n",
    "                    {\"args\": [10**9, 10**9], \"kwargs\": {}, \"expect\": 2000000000},\n",
    "                ]\n",
    "            }\n",
    "        },\n",
    "    },\n",
    "\n",
    "    # 2) print_hello_world\n",
    "    {\n",
    "        \"inputs\": {\"code\": \"def print_hello_world() -> None:\\n    print('Hello, World!')\"},\n",
    "        \"outputs\": {\n",
    "            \"tests\": {\n",
    "                \"function_name\": \"print_hello_world\",\n",
    "                \"tests\": [\n",
    "                    {\"args\": [], \"kwargs\": {}, \"expect\": None}\n",
    "                ]\n",
    "            }\n",
    "        },\n",
    "    },\n",
    "\n",
    "    # 3) concatenate_strings\n",
    "    {\n",
    "        \"inputs\": {\"code\": \"def concatenate_strings(a: str, b: str) -> str:\\n    return a + ' ' + b\"},\n",
    "        \"outputs\": {\n",
    "            \"tests\": {\n",
    "                \"function_name\": \"concatenate_strings\",\n",
    "                \"tests\": [\n",
    "                    {\"args\": [\"hello\", \"world\"], \"kwargs\": {}, \"expect\": \"hello world\"},\n",
    "                    {\"args\": [\"\", \"\"], \"kwargs\": {}, \"expect\": \" \"},\n",
    "                    {\"args\": [\"hello\", \"\"], \"kwargs\": {}, \"expect\": \"hello \"},\n",
    "                    {\"args\": [\"\", \"world\"], \"kwargs\": {}, \"expect\": \" world\"},\n",
    "                ]\n",
    "            }\n",
    "        },\n",
    "    },\n",
    "\n",
    "    # 4) factorial\n",
    "    {\n",
    "        \"inputs\": {\"code\": \"def factorial(n: int) -> int:\\n    return 1 if n == 0 else n * factorial(n - 1)\"},\n",
    "        \"outputs\": {\n",
    "            \"tests\": {\n",
    "                \"function_name\": \"factorial\",\n",
    "                \"tests\": [\n",
    "                    {\"args\": [0], \"kwargs\": {}, \"expect\": 1},\n",
    "                    {\"args\": [1], \"kwargs\": {}, \"expect\": 1},\n",
    "                    {\"args\": [5], \"kwargs\": {}, \"expect\": 120},\n",
    "                ]\n",
    "            }\n",
    "        },\n",
    "    },\n",
    "\n",
    "    # 5) is_even\n",
    "    {\n",
    "        \"inputs\": {\"code\": \"def is_even(n: int) -> bool:\\n    return n % 2 == 0\"},\n",
    "        \"outputs\": {\n",
    "            \"tests\": {\n",
    "                \"function_name\": \"is_even\",\n",
    "                \"tests\": [\n",
    "                    {\"args\": [2], \"kwargs\": {}, \"expect\": True},\n",
    "                    {\"args\": [3], \"kwargs\": {}, \"expect\": False},\n",
    "                    {\"args\": [0], \"kwargs\": {}, \"expect\": True},\n",
    "                    {\"args\": [-4], \"kwargs\": {}, \"expect\": True},\n",
    "                ]\n",
    "            }\n",
    "        },\n",
    "    },\n",
    "\n",
    "    # 6) reverse_list\n",
    "    {\n",
    "        \"inputs\": {\"code\": \"def reverse_list(lst: list) -> list:\\n    return lst[::-1]\"},\n",
    "        \"outputs\": {\n",
    "            \"tests\": {\n",
    "                \"function_name\": \"reverse_list\",\n",
    "                \"tests\": [\n",
    "                    {\"args\": [[1, 2, 3]], \"kwargs\": {}, \"expect\": [3, 2, 1]},\n",
    "                    {\"args\": [[]], \"kwargs\": {}, \"expect\": []},\n",
    "                    {\"args\": [[\"a\", \"b\"]], \"kwargs\": {}, \"expect\": [\"b\", \"a\"]},\n",
    "                ]\n",
    "            }\n",
    "        },\n",
    "    },\n",
    "\n",
    "    # 7) get_max\n",
    "    {\n",
    "        \"inputs\": {\"code\": \"def get_max(a: int, b: int) -> int:\\n    return a if a > b else b\"},\n",
    "        \"outputs\": {\n",
    "            \"tests\": {\n",
    "                \"function_name\": \"get_max\",\n",
    "                \"tests\": [\n",
    "                    {\"args\": [1, 2], \"kwargs\": {}, \"expect\": 2},\n",
    "                    {\"args\": [5, 5], \"kwargs\": {}, \"expect\": 5},\n",
    "                    {\"args\": [-1, -5], \"kwargs\": {}, \"expect\": -1},\n",
    "                ]\n",
    "            }\n",
    "        },\n",
    "    },\n",
    "\n",
    "    # 8) join_words\n",
    "    {\n",
    "        \"inputs\": {\"code\": \"def join_words(words: list[str], sep: str = ',') -> str:\\n    return sep.join(words)\"},\n",
    "        \"outputs\": {\n",
    "            \"tests\": {\n",
    "                \"function_name\": \"join_words\",\n",
    "                \"tests\": [\n",
    "                    {\"args\": [[\"a\", \"b\", \"c\"]], \"kwargs\": {}, \"expect\": \"a,b,c\"},\n",
    "                    {\"args\": [[\"a\", \"b\"]], \"kwargs\": {\"sep\": \"-\"}, \"expect\": \"a-b\"},\n",
    "                    {\"args\": [[]], \"kwargs\": {}, \"expect\": \"\"},\n",
    "                ]\n",
    "            }\n",
    "        },\n",
    "    },\n",
    "]\n",
    "\n",
    "# Create (or append to) the dataset\n",
    "dataset = client.create_dataset(dataset_name) if not client.has_dataset(dataset_name=dataset_name) \\\n",
    "          else client.read_dataset(dataset_name=dataset_name)\n",
    "\n",
    "client.create_examples(dataset_id=dataset.id, examples=examples)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7db0493a",
   "metadata": {},
   "outputs": [],
   "source": [
    "grader_instructions_for_tests = \"\"\"\n",
    "You are grading a student's JSON test suite for a given Python function.\n",
    "\n",
    "You are given:\n",
    "- QUESTION: the task the tests target (the input code’s behavior)\n",
    "- GROUND_TRUTH: a correct JSON test suite for that function\n",
    "- STUDENT_RESPONSE: the student's JSON (should be a JSON object)\n",
    "\n",
    "Grade ONLY for structural validity and factual alignment to ground-truth behavior.\n",
    "\n",
    "RUBRIC\n",
    "1) Must be valid JSON (no Markdown/prose). Top-level keys:\n",
    "   - \"function_name\": string\n",
    "   - \"tests\": array of objects with keys {\"args\": array, \"kwargs\": object, \"expect\": any}\n",
    "2) All args/kwargs/expect must be JSON-serializable.\n",
    "3) Tests must cover the happy path and at least two edge cases relevant to the function.\n",
    "4) Extra tests are OK if consistent with the function’s true behavior.\n",
    "5) Function name must match the target function in the input code.\n",
    "\n",
    "Correctness:\n",
    "True means that the students response meets all the criteria.\n",
    "False means that the students response does not meet all the criteria.\n",
    "\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "69da02ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# LLM as a Judge Output schema\n",
    "class Grade(TypedDict):\n",
    "    \"\"\"Compare the expected and actual answer and grade the actual answer\"\"\"\n",
    "\n",
    "    reasoning: Annotated[\n",
    "        str, ..., \"Explain your reasoning whether the actual response is correct or not\"\n",
    "    ]\n",
    "    is_correct: Annotated[\n",
    "        bool, ..., \"True if the student response is correct, False if it is not\"\n",
    "    ]\n",
    "\n",
    "\n",
    "grader_llm = init_chat_model(model=\"gpt-4o\", temperature=0).with_structured_output(\n",
    "    Grade\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "275f36ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "def correctness(\n",
    "    inputs: dict, outputs: dict, reference_outputs: dict\n",
    ") -> bool:\n",
    "    \"\"\"Evaluate if the final answer is correct\"\"\"\n",
    "\n",
    "    user_instruction = f\"\"\"\n",
    "    QUESTION: {inputs[\"code\"]}\n",
    "    GROUND TRUTH RESPONSE: {reference_outputs[\"tests\"]}\n",
    "    STUDENT'S RESPONSE: {outputs[\"tests\"]}\n",
    "    \"\"\"\n",
    "\n",
    "    grade = grader_llm.invoke(\n",
    "        [\n",
    "            {\"role\": \"system\", \"content\": grader_instructions_for_tests},\n",
    "            {\"role\": \"user\", \"content\": user_instruction},\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    return grade[\"is_correct\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5611a8c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def target_function(inputs: dict) -> dict:\n",
    "   \n",
    "    #Invoke the generate_code node\n",
    "    result = graph.nodes[\"generate_test\"].invoke(inputs)\n",
    "    \n",
    "    \n",
    "    return {\"tests\": result.update[\"tests\"]}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "02ccfa0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "View the evaluation results for experiment: 'test_the_correct_tests_are_generated-563cf512' at:\n",
      "https://smith.langchain.com/o/5e26199c-44b7-5d71-a174-0781dc496380/datasets/1cc9ffbc-7579-4b4b-b21f-fde01facb340/compare?selectedSessions=7cf99e8e-d108-4fee-ac5f-385325bb7cd1\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1it [00:08,  8.12s/it]Error running target function: Expecting ',' delimiter: line 5 column 28 (char 153)\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/jameskanyiri/LANGGRAPH/langgraph_coding_agent_workflow/.venv/lib/python3.13/site-packages/langsmith/evaluation/_runner.py\", line 1924, in _forward\n",
      "    fn(*args, langsmith_extra=langsmith_extra)\n",
      "    ~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/var/folders/lx/47jl9ym97js4vymgwnc01kww0000gn/T/ipykernel_46279/2221717457.py\", line 4, in target_function\n",
      "    result = graph.nodes[\"generate_test\"].invoke(inputs)\n",
      "  File \"/Users/jameskanyiri/LANGGRAPH/langgraph_coding_agent_workflow/.venv/lib/python3.13/site-packages/langgraph/pregel/_read.py\", line 234, in invoke\n",
      "    return self.bound.invoke(\n",
      "           ~~~~~~~~~~~~~~~~~^\n",
      "        input,\n",
      "        ^^^^^^\n",
      "        merge_configs({\"metadata\": self.metadata, \"tags\": self.tags}, config),\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "        **kwargs,\n",
      "        ^^^^^^^^^\n",
      "    )\n",
      "    ^\n",
      "  File \"/Users/jameskanyiri/LANGGRAPH/langgraph_coding_agent_workflow/.venv/lib/python3.13/site-packages/langgraph/_internal/_runnable.py\", line 401, in invoke\n",
      "    ret = self.func(*args, **kwargs)\n",
      "  File \"/Users/jameskanyiri/LANGGRAPH/langgraph_coding_agent_workflow/src/nodes/generate_test.py\", line 62, in generate_test\n",
      "    tests = json.loads(response.content)\n",
      "  File \"/opt/homebrew/Cellar/python@3.13/3.13.3/Frameworks/Python.framework/Versions/3.13/lib/python3.13/json/__init__.py\", line 346, in loads\n",
      "    return _default_decoder.decode(s)\n",
      "           ~~~~~~~~~~~~~~~~~~~~~~~^^^\n",
      "  File \"/opt/homebrew/Cellar/python@3.13/3.13.3/Frameworks/Python.framework/Versions/3.13/lib/python3.13/json/decoder.py\", line 345, in decode\n",
      "    obj, end = self.raw_decode(s, idx=_w(s, 0).end())\n",
      "               ~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/homebrew/Cellar/python@3.13/3.13.3/Frameworks/Python.framework/Versions/3.13/lib/python3.13/json/decoder.py\", line 361, in raw_decode\n",
      "    obj, end = self.scan_once(s, idx)\n",
      "               ~~~~~~~~~~~~~~^^^^^^^^\n",
      "json.decoder.JSONDecodeError: Expecting ',' delimiter: line 5 column 28 (char 153)\n",
      "Error running evaluator <DynamicRunEvaluator correctness> on run 30bbf027-dcd5-444d-a93a-19231eab3b1c: KeyError('tests')\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/jameskanyiri/LANGGRAPH/langgraph_coding_agent_workflow/.venv/lib/python3.13/site-packages/langsmith/evaluation/_runner.py\", line 1620, in _run_evaluators\n",
      "    evaluator_response = evaluator.evaluate_run(  # type: ignore[call-arg]\n",
      "        run=run,\n",
      "        example=example,\n",
      "        evaluator_run_id=evaluator_run_id,\n",
      "    )\n",
      "  File \"/Users/jameskanyiri/LANGGRAPH/langgraph_coding_agent_workflow/.venv/lib/python3.13/site-packages/langsmith/evaluation/evaluator.py\", line 351, in evaluate_run\n",
      "    result = self.func(\n",
      "        run,\n",
      "        example,\n",
      "        langsmith_extra={\"run_id\": evaluator_run_id, \"metadata\": metadata},\n",
      "    )\n",
      "  File \"/Users/jameskanyiri/LANGGRAPH/langgraph_coding_agent_workflow/.venv/lib/python3.13/site-packages/langsmith/evaluation/evaluator.py\", line 777, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/var/folders/lx/47jl9ym97js4vymgwnc01kww0000gn/T/ipykernel_46279/3682001800.py\", line 9, in correctness\n",
      "    STUDENT'S RESPONSE: {outputs[\"tests\"]}\n",
      "                         ~~~~~~~^^^^^^^^^\n",
      "KeyError: 'tests'\n",
      "8it [00:44,  5.29s/it]Error running target function: Expecting ',' delimiter: line 5 column 28 (char 153)\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/jameskanyiri/LANGGRAPH/langgraph_coding_agent_workflow/.venv/lib/python3.13/site-packages/langsmith/evaluation/_runner.py\", line 1924, in _forward\n",
      "    fn(*args, langsmith_extra=langsmith_extra)\n",
      "    ~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/var/folders/lx/47jl9ym97js4vymgwnc01kww0000gn/T/ipykernel_46279/2221717457.py\", line 4, in target_function\n",
      "    result = graph.nodes[\"generate_test\"].invoke(inputs)\n",
      "  File \"/Users/jameskanyiri/LANGGRAPH/langgraph_coding_agent_workflow/.venv/lib/python3.13/site-packages/langgraph/pregel/_read.py\", line 234, in invoke\n",
      "    return self.bound.invoke(\n",
      "           ~~~~~~~~~~~~~~~~~^\n",
      "        input,\n",
      "        ^^^^^^\n",
      "        merge_configs({\"metadata\": self.metadata, \"tags\": self.tags}, config),\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "        **kwargs,\n",
      "        ^^^^^^^^^\n",
      "    )\n",
      "    ^\n",
      "  File \"/Users/jameskanyiri/LANGGRAPH/langgraph_coding_agent_workflow/.venv/lib/python3.13/site-packages/langgraph/_internal/_runnable.py\", line 401, in invoke\n",
      "    ret = self.func(*args, **kwargs)\n",
      "  File \"/Users/jameskanyiri/LANGGRAPH/langgraph_coding_agent_workflow/src/nodes/generate_test.py\", line 62, in generate_test\n",
      "    tests = json.loads(response.content)\n",
      "  File \"/opt/homebrew/Cellar/python@3.13/3.13.3/Frameworks/Python.framework/Versions/3.13/lib/python3.13/json/__init__.py\", line 346, in loads\n",
      "    return _default_decoder.decode(s)\n",
      "           ~~~~~~~~~~~~~~~~~~~~~~~^^^\n",
      "  File \"/opt/homebrew/Cellar/python@3.13/3.13.3/Frameworks/Python.framework/Versions/3.13/lib/python3.13/json/decoder.py\", line 345, in decode\n",
      "    obj, end = self.raw_decode(s, idx=_w(s, 0).end())\n",
      "               ~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/homebrew/Cellar/python@3.13/3.13.3/Frameworks/Python.framework/Versions/3.13/lib/python3.13/json/decoder.py\", line 361, in raw_decode\n",
      "    obj, end = self.scan_once(s, idx)\n",
      "               ~~~~~~~~~~~~~~^^^^^^^^\n",
      "json.decoder.JSONDecodeError: Expecting ',' delimiter: line 5 column 28 (char 153)\n",
      "Error running evaluator <DynamicRunEvaluator correctness> on run 2bfb742a-ea5a-4273-a436-11dedc60cbc0: KeyError('tests')\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/jameskanyiri/LANGGRAPH/langgraph_coding_agent_workflow/.venv/lib/python3.13/site-packages/langsmith/evaluation/_runner.py\", line 1620, in _run_evaluators\n",
      "    evaluator_response = evaluator.evaluate_run(  # type: ignore[call-arg]\n",
      "        run=run,\n",
      "        example=example,\n",
      "        evaluator_run_id=evaluator_run_id,\n",
      "    )\n",
      "  File \"/Users/jameskanyiri/LANGGRAPH/langgraph_coding_agent_workflow/.venv/lib/python3.13/site-packages/langsmith/evaluation/evaluator.py\", line 351, in evaluate_run\n",
      "    result = self.func(\n",
      "        run,\n",
      "        example,\n",
      "        langsmith_extra={\"run_id\": evaluator_run_id, \"metadata\": metadata},\n",
      "    )\n",
      "  File \"/Users/jameskanyiri/LANGGRAPH/langgraph_coding_agent_workflow/.venv/lib/python3.13/site-packages/langsmith/evaluation/evaluator.py\", line 777, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/var/folders/lx/47jl9ym97js4vymgwnc01kww0000gn/T/ipykernel_46279/3682001800.py\", line 9, in correctness\n",
      "    STUDENT'S RESPONSE: {outputs[\"tests\"]}\n",
      "                         ~~~~~~~^^^^^^^^^\n",
      "KeyError: 'tests'\n",
      "16it [01:24,  5.39s/it]Error running target function: Expecting ',' delimiter: line 5 column 28 (char 153)\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/jameskanyiri/LANGGRAPH/langgraph_coding_agent_workflow/.venv/lib/python3.13/site-packages/langsmith/evaluation/_runner.py\", line 1924, in _forward\n",
      "    fn(*args, langsmith_extra=langsmith_extra)\n",
      "    ~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/var/folders/lx/47jl9ym97js4vymgwnc01kww0000gn/T/ipykernel_46279/2221717457.py\", line 4, in target_function\n",
      "    result = graph.nodes[\"generate_test\"].invoke(inputs)\n",
      "  File \"/Users/jameskanyiri/LANGGRAPH/langgraph_coding_agent_workflow/.venv/lib/python3.13/site-packages/langgraph/pregel/_read.py\", line 234, in invoke\n",
      "    return self.bound.invoke(\n",
      "           ~~~~~~~~~~~~~~~~~^\n",
      "        input,\n",
      "        ^^^^^^\n",
      "        merge_configs({\"metadata\": self.metadata, \"tags\": self.tags}, config),\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "        **kwargs,\n",
      "        ^^^^^^^^^\n",
      "    )\n",
      "    ^\n",
      "  File \"/Users/jameskanyiri/LANGGRAPH/langgraph_coding_agent_workflow/.venv/lib/python3.13/site-packages/langgraph/_internal/_runnable.py\", line 401, in invoke\n",
      "    ret = self.func(*args, **kwargs)\n",
      "  File \"/Users/jameskanyiri/LANGGRAPH/langgraph_coding_agent_workflow/src/nodes/generate_test.py\", line 62, in generate_test\n",
      "    tests = json.loads(response.content)\n",
      "  File \"/opt/homebrew/Cellar/python@3.13/3.13.3/Frameworks/Python.framework/Versions/3.13/lib/python3.13/json/__init__.py\", line 346, in loads\n",
      "    return _default_decoder.decode(s)\n",
      "           ~~~~~~~~~~~~~~~~~~~~~~~^^^\n",
      "  File \"/opt/homebrew/Cellar/python@3.13/3.13.3/Frameworks/Python.framework/Versions/3.13/lib/python3.13/json/decoder.py\", line 345, in decode\n",
      "    obj, end = self.raw_decode(s, idx=_w(s, 0).end())\n",
      "               ~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/homebrew/Cellar/python@3.13/3.13.3/Frameworks/Python.framework/Versions/3.13/lib/python3.13/json/decoder.py\", line 361, in raw_decode\n",
      "    obj, end = self.scan_once(s, idx)\n",
      "               ~~~~~~~~~~~~~~^^^^^^^^\n",
      "json.decoder.JSONDecodeError: Expecting ',' delimiter: line 5 column 28 (char 153)\n",
      "Error running evaluator <DynamicRunEvaluator correctness> on run 6257ad48-0d73-4060-97a2-ad8f6ee5bde4: KeyError('tests')\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/jameskanyiri/LANGGRAPH/langgraph_coding_agent_workflow/.venv/lib/python3.13/site-packages/langsmith/evaluation/_runner.py\", line 1620, in _run_evaluators\n",
      "    evaluator_response = evaluator.evaluate_run(  # type: ignore[call-arg]\n",
      "        run=run,\n",
      "        example=example,\n",
      "        evaluator_run_id=evaluator_run_id,\n",
      "    )\n",
      "  File \"/Users/jameskanyiri/LANGGRAPH/langgraph_coding_agent_workflow/.venv/lib/python3.13/site-packages/langsmith/evaluation/evaluator.py\", line 351, in evaluate_run\n",
      "    result = self.func(\n",
      "        run,\n",
      "        example,\n",
      "        langsmith_extra={\"run_id\": evaluator_run_id, \"metadata\": metadata},\n",
      "    )\n",
      "  File \"/Users/jameskanyiri/LANGGRAPH/langgraph_coding_agent_workflow/.venv/lib/python3.13/site-packages/langsmith/evaluation/evaluator.py\", line 777, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/var/folders/lx/47jl9ym97js4vymgwnc01kww0000gn/T/ipykernel_46279/3682001800.py\", line 9, in correctness\n",
      "    STUDENT'S RESPONSE: {outputs[\"tests\"]}\n",
      "                         ~~~~~~~^^^^^^^^^\n",
      "KeyError: 'tests'\n",
      "24it [02:02,  5.13s/it]Error running target function: Expecting ',' delimiter: line 5 column 28 (char 153)\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/jameskanyiri/LANGGRAPH/langgraph_coding_agent_workflow/.venv/lib/python3.13/site-packages/langsmith/evaluation/_runner.py\", line 1924, in _forward\n",
      "    fn(*args, langsmith_extra=langsmith_extra)\n",
      "    ~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/var/folders/lx/47jl9ym97js4vymgwnc01kww0000gn/T/ipykernel_46279/2221717457.py\", line 4, in target_function\n",
      "    result = graph.nodes[\"generate_test\"].invoke(inputs)\n",
      "  File \"/Users/jameskanyiri/LANGGRAPH/langgraph_coding_agent_workflow/.venv/lib/python3.13/site-packages/langgraph/pregel/_read.py\", line 234, in invoke\n",
      "    return self.bound.invoke(\n",
      "           ~~~~~~~~~~~~~~~~~^\n",
      "        input,\n",
      "        ^^^^^^\n",
      "        merge_configs({\"metadata\": self.metadata, \"tags\": self.tags}, config),\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "        **kwargs,\n",
      "        ^^^^^^^^^\n",
      "    )\n",
      "    ^\n",
      "  File \"/Users/jameskanyiri/LANGGRAPH/langgraph_coding_agent_workflow/.venv/lib/python3.13/site-packages/langgraph/_internal/_runnable.py\", line 401, in invoke\n",
      "    ret = self.func(*args, **kwargs)\n",
      "  File \"/Users/jameskanyiri/LANGGRAPH/langgraph_coding_agent_workflow/src/nodes/generate_test.py\", line 62, in generate_test\n",
      "    tests = json.loads(response.content)\n",
      "  File \"/opt/homebrew/Cellar/python@3.13/3.13.3/Frameworks/Python.framework/Versions/3.13/lib/python3.13/json/__init__.py\", line 346, in loads\n",
      "    return _default_decoder.decode(s)\n",
      "           ~~~~~~~~~~~~~~~~~~~~~~~^^^\n",
      "  File \"/opt/homebrew/Cellar/python@3.13/3.13.3/Frameworks/Python.framework/Versions/3.13/lib/python3.13/json/decoder.py\", line 345, in decode\n",
      "    obj, end = self.raw_decode(s, idx=_w(s, 0).end())\n",
      "               ~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/homebrew/Cellar/python@3.13/3.13.3/Frameworks/Python.framework/Versions/3.13/lib/python3.13/json/decoder.py\", line 361, in raw_decode\n",
      "    obj, end = self.scan_once(s, idx)\n",
      "               ~~~~~~~~~~~~~~^^^^^^^^\n",
      "json.decoder.JSONDecodeError: Expecting ',' delimiter: line 5 column 28 (char 153)\n",
      "Error running evaluator <DynamicRunEvaluator correctness> on run 00132642-bb84-4419-9793-cec64a801ce4: KeyError('tests')\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/jameskanyiri/LANGGRAPH/langgraph_coding_agent_workflow/.venv/lib/python3.13/site-packages/langsmith/evaluation/_runner.py\", line 1620, in _run_evaluators\n",
      "    evaluator_response = evaluator.evaluate_run(  # type: ignore[call-arg]\n",
      "        run=run,\n",
      "        example=example,\n",
      "        evaluator_run_id=evaluator_run_id,\n",
      "    )\n",
      "  File \"/Users/jameskanyiri/LANGGRAPH/langgraph_coding_agent_workflow/.venv/lib/python3.13/site-packages/langsmith/evaluation/evaluator.py\", line 351, in evaluate_run\n",
      "    result = self.func(\n",
      "        run,\n",
      "        example,\n",
      "        langsmith_extra={\"run_id\": evaluator_run_id, \"metadata\": metadata},\n",
      "    )\n",
      "  File \"/Users/jameskanyiri/LANGGRAPH/langgraph_coding_agent_workflow/.venv/lib/python3.13/site-packages/langsmith/evaluation/evaluator.py\", line 777, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/var/folders/lx/47jl9ym97js4vymgwnc01kww0000gn/T/ipykernel_46279/3682001800.py\", line 9, in correctness\n",
      "    STUDENT'S RESPONSE: {outputs[\"tests\"]}\n",
      "                         ~~~~~~~^^^^^^^^^\n",
      "KeyError: 'tests'\n",
      "32it [02:40,  5.01s/it]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "experiment_results = client.evaluate(\n",
    "    target_function,\n",
    "    data=dataset_name,\n",
    "    evaluators=[correctness],\n",
    "    experiment_prefix=\"test_the_correct_tests_are_generated\",\n",
    ")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
