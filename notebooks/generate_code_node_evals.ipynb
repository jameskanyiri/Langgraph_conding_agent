{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 197,
   "id": "f39c9143",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "sys.path.append(os.path.abspath(\"..\"))\n",
    "\n",
    "from langsmith import Client\n",
    "from typing import TypedDict\n",
    "from typing_extensions import Annotated\n",
    "from langchain.chat_models import init_chat_model\n",
    "from src.agent import graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "id": "f83c0ab2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'example_ids': ['e176addc-0443-4e95-a74e-34db446be41d',\n",
       "  'fa4f2525-c14c-4063-b033-63e80fd2ee78',\n",
       "  'c9dd033e-4486-4f4d-be7c-2be8ef38114f'],\n",
       " 'count': 3}"
      ]
     },
     "execution_count": 198,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langsmith import Client\n",
    "from langchain_core.messages import HumanMessage\n",
    "\n",
    "client = Client()\n",
    "dataset_name = \"test_the_correct_code_is_generated\"\n",
    "\n",
    "# Original examples (with HumanMessage objects)\n",
    "examples = [\n",
    "    {\n",
    "        \"inputs\": {\n",
    "            \"messages\": [\n",
    "                {\"role\": \"user\", \"content\": \"I want a function to add two numbers\"}\n",
    "            ]\n",
    "        },\n",
    "        \"outputs\": {\n",
    "            \"code\": \"def add_two_numbers(a: int, b: int) -> int:\\n    return a + b\"\n",
    "        },\n",
    "    },\n",
    "    {\n",
    "        \"inputs\": {\n",
    "            \"messages\": [\n",
    "                {\n",
    "                    \"role\": \"user\",\n",
    "                    \"content\": \"I want a function to print 'Hello, World!'\",\n",
    "                }\n",
    "            ]\n",
    "        },\n",
    "        \"outputs\": {\"code\": \"def print_hello_world():\\n    print('Hello, World!')\"},\n",
    "    },\n",
    "    {\n",
    "        \"inputs\": {\n",
    "            \"messages\": [\n",
    "                {\n",
    "                    \"role\": \"user\",\n",
    "                    \"content\": \"I want a function to concatenate two strings with a space in between\",\n",
    "                }\n",
    "            ]\n",
    "        },\n",
    "        \"outputs\": {\n",
    "            \"code\": \"def concatenate_strings(a: str, b: str) -> str:\\n    return a + ' ' + b\"\n",
    "        },\n",
    "    },\n",
    "]\n",
    "\n",
    "\n",
    "# Create (or append to) the dataset using converted inputs\n",
    "if not client.has_dataset(dataset_name=dataset_name):\n",
    "    dataset = client.create_dataset(dataset_name)\n",
    "else:\n",
    "    dataset = client.read_dataset(dataset_name=dataset_name)\n",
    "\n",
    "client.create_examples(dataset_id=dataset.id, examples=examples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "id": "7db0493a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# LLM as a Judge Instruction\n",
    "grader_instructions = \"\"\" \n",
    "\n",
    "You are a teacher grading a  student's code.\n",
    "\n",
    "You will be given a QUESTION, the GROUND TRUTH (correct) RESPONSE and the STUDENT'S RESPONSE.\n",
    "\n",
    "Here is the grading criteria to follow:\n",
    "(1) Grade the student responses based ONLY on their factual accuracy to the ground truth answer.]\n",
    "(2) Ensure that the student response is a valid Python code.\n",
    "(3) Ensure the student response does not include any markdown, comments, or extra text outside the JSON.\n",
    "(4) It is CORRECT if the student response contains more information than the ground truth response, as long as it is factually accurate relative to the  ground truth response.\n",
    "\n",
    "\n",
    "Correctness:\n",
    "True means that the students response meets all the criteria.\n",
    "False means that the students response does not meet all the criteria.\n",
    "\n",
    "Explain  your reasoning in a step by step manner to ensure your reasoning and  conclusion is correct.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "id": "69da02ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# LLM as a Judge Output schema\n",
    "class Grade(TypedDict):\n",
    "    \"\"\"Compare the expected and actual answer and grade the actual answer\"\"\"\n",
    "\n",
    "    reasoning: Annotated[\n",
    "        str, ..., \"Explain your reasoning whether the actual response is correct or not\"\n",
    "    ]\n",
    "    is_correct: Annotated[\n",
    "        bool, ..., \"True if the student response is correct, False if it is not\"\n",
    "    ]\n",
    "\n",
    "\n",
    "grader_llm = init_chat_model(model=\"gpt-4o\", temperature=0).with_structured_output(\n",
    "    Grade\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "275f36ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "def correctness(\n",
    "    inputs: dict, outputs: dict, reference_outputs: dict\n",
    ") -> bool:\n",
    "    \"\"\"Evaluate if the final answer is correct\"\"\"\n",
    "\n",
    "    user_instruction = f\"\"\"\n",
    "    QUESTION: {inputs[\"messages\"][-1]}\n",
    "    GROUND TRUTH RESPONSE: {reference_outputs[\"code\"]}\n",
    "    STUDENT'S RESPONSE: {outputs}\n",
    "    \"\"\"\n",
    "\n",
    "    grade = grader_llm.invoke(\n",
    "        [\n",
    "            {\"role\": \"system\", \"content\": grader_instructions},\n",
    "            {\"role\": \"user\", \"content\": user_instruction},\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    return grade[\"is_correct\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "id": "3ad3ffe5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.messages import HumanMessage\n",
    "\n",
    "inputs = {\n",
    "    \"messages\": [\n",
    "        HumanMessage(content=\"I want a function to concatenate two strings with a space in between\")\n",
    "    ]\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5611a8c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Any, Dict, List\n",
    "from langchain_core.messages import BaseMessage, HumanMessage\n",
    "\n",
    "def target_function(inputs: Dict[str, Any]) -> Dict[str, str]:\n",
    "    \n",
    "    #Get the messages from the dataset\n",
    "    msgs: List[Any] = inputs.get(\"messages\", [])\n",
    "\n",
    "    #Convert to langchain messages object\n",
    "    msgs = [\n",
    "        HumanMessage(content=(m.get(\"content\", \"\") if isinstance(m, dict) else str(m)))\n",
    "        for m in msgs\n",
    "    ]\n",
    "\n",
    "    #Invoke the generate_code node\n",
    "    result = graph.nodes[\"generate_code\"].invoke({\"messages\": msgs})\n",
    "    \n",
    "    \n",
    "    return {\"code\": result.update[\"code\"]}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "id": "3d94d35b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'code': 'def concatenate_strings_with_space(str1: str, str2: str) -> str:\\n    return str1 + \" \" + str2'}"
      ]
     },
     "execution_count": 204,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_function(inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02ccfa0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "View the evaluation results for experiment: 'test_the_correct_code_is_generated-1b6d4252' at:\n",
      "https://smith.langchain.com/o/5e26199c-44b7-5d71-a174-0781dc496380/datasets/f7cffa21-1bc1-4d1b-8932-915778416070/compare?selectedSessions=b83669aa-14f7-45cc-86fa-f38ad1f2f77f\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "6it [00:18,  3.14s/it]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "experiment_results = client.evaluate(\n",
    "    target_function,\n",
    "    data=dataset_name,\n",
    "    evaluators=[correctness],\n",
    "    experiment_prefix=\"test_the_correct_code_is_generated\",\n",
    ")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
